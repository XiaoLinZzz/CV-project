{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFi4isLLqWzS"
      },
      "source": [
        "# **Flower Classification Competition (40%)**\n",
        "For this competition, we will use the Flower Recognition (https://cloudstor.aarnet.edu.au/plus/s/1n6XuPUCwJ0MkgN). This dataset contains 4317 images of flowers. The data collection is based on the data flicr, google images, yandex images. You can use this datastet to recognize plants from the photo.  \n",
        "\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion. For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions!\n",
        "\n",
        "We provide a baseline by the following steps:\n",
        "\n",
        "*   Loding and Analysing the Flowers dataset using torchvision.\n",
        "*   Defining a simple convolutional neural network. \n",
        "*   How to use existing loss function for the model learning. \n",
        "*   Train the network on the training data. \n",
        "*   Test the trained network on the testing data. \n",
        "*   Generate prediction for the random test image(s). \n",
        "\n",
        "The following trick/tweak(s) could be considered:\n",
        "-------\n",
        "1. Change of advanced training parameters: Learning Rate, Optimizer, Batch-size, Number of Max Epochs, and Drop-out. \n",
        "2. Use of a new loss function.\n",
        "3. Data augmentation\n",
        "4. Architectural Changes: Batch Normalization, Residual layers, Attention Block, and other varients.\n",
        "\n",
        "Your code should be modified from the provided baseline. A pdf report is required to explain the tricks you employed, and the imporvements they achieved.\n",
        "Marking Rules:\n",
        "-------\n",
        "We will mark the competition based on the final test accuracy on testing images and your report.\n",
        "\n",
        "Final mark = acc_mark + efficiency mark + report mark + bonus mark\n",
        "###Acc_mark 15:\n",
        "\n",
        "We will rank all the submission results based on their test accuracy. The top 30% of the students will get full marks.\n",
        "\n",
        "|Accuracy|Mark|\n",
        "|---|---|\n",
        "| Top 30% in the class|          15|\n",
        "|30%-50%|         11|\n",
        "|50%-80%  |        7|\n",
        "| 80%-90%  |      3|\n",
        "| 90%-100%  |      1|\n",
        "|Not implemented| 0|\n",
        "\n",
        "###Efficiency mark 5:\n",
        "\n",
        "Efficiency is evaluated by the computational costs (flops: https://en.wikipedia.org/wiki/FLOPS). Please report the computational costs for your final model and attach the code/process about how you calculate it.\n",
        "\n",
        "|Efficiency|Mark|\n",
        "|---|---|\n",
        "| Top 30% in the class|          5|\n",
        "|30%-50%|         4|\n",
        "|50%-80%  |        3|\n",
        "| 80%-90%  |      2|\n",
        "| 90%-100%  |      2|\n",
        "|Not implemented| 0|\n",
        "\n",
        "###Report mark 20:\n",
        "1. Introduction and your understanding to the baseline model: 2 points\n",
        "\n",
        "2. Employed more than three tricks with ablation studies to improve the accuracy: 6 points\n",
        "\n",
        "Clearly explain the reference, motivation and design choice for each trick/tweak(s). Providing the experimental results in tables.\n",
        "Example table:\n",
        "\n",
        "|Trick1|Trick2|Trick3|Accuracy|\n",
        "|---|---|---|---|\n",
        "|N|N|N|60%|\n",
        "|Y|N|N|65%|\n",
        "|Y|Y|N|77%|\n",
        "|Y|Y|Y|82%|\n",
        "\n",
        "Observation and discussion based on the experiment results.\n",
        "\n",
        "3. Expaination of the methods on reducing the computational cost and/or improve the trade-off between accuracy and efficiency: 4 points\n",
        "\n",
        "4. Explaination of the code implementationï¼š3 points\n",
        "\n",
        "5. Visulization results: e.g. training and testing accuracy/loss for each model, case studies: 3 points\n",
        "\n",
        "6. Open ended:  Limitations, conclusions, failure cases analysis...: 2 points\n",
        "\n",
        "###Bouns mark:\n",
        "1. Top three results: 2 points\n",
        "2. Fancy designs: 2 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "21p5S0cCYPwN"
      },
      "outputs": [],
      "source": [
        "##################################################################################################################################\n",
        "### Subject: Computer Vision \n",
        "### Year: 2022\n",
        "### Student Name: Lujie Ma, Wenlong Dai\n",
        "### Student ID: a1810558, a1777081\n",
        "### Comptetion Name: Flowers Classification Competition\n",
        "### Final Results:\n",
        "### ACC:         FLOPs:\n",
        "##################################################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I0d4smZzvzWH"
      },
      "outputs": [],
      "source": [
        "# Importing libraries. \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "# To avoid non-essential warnings \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models \n",
        "from torchvision.utils import make_grid\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE2dpR5MJJSx",
        "outputId": "b34eecd5-af67-4b94-bf96-09d87be34d8d"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'CLOUDSDK_CONFIG'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-823dc44e82a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reference: https://towardsdatascience.com/google-colab-import-and-export-datasets-eccf801e2971\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Dataset path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   root_dir = _os.path.realpath(\n\u001b[0;32m---> 43\u001b[0;31m       _os.path.join(_os.environ['CLOUDSDK_CONFIG'], '../..'))\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0minet_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IPV4_ONLY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/fuse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CLOUDSDK_CONFIG'"
          ]
        }
      ],
      "source": [
        "# Mounting G-Drive to get your dataset. \n",
        "# To access Google Colab GPU; Go To: Edit >>> Network Settings >>> Hardware Accelarator: Select GPU. \n",
        "# Reference: https://towardsdatascience.com/google-colab-import-and-export-datasets-eccf801e2971 \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset path.\n",
        "data_directory = '/content/drive/MyDrive/Dataset/flower_data/flower_kaggle/flowers'\n",
        "dataset=datasets.ImageFolder(root=data_directory,transform=train_transform)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCB13oubv4es"
      },
      "outputs": [],
      "source": [
        "# Performing Image Transformations. \n",
        "\n",
        "train_transform=transforms.Compose([\n",
        "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
        "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
        "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
        "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qm4fSHNv8uV",
        "outputId": "218f28c1-7aca-4433-c574-8ac98cdcd9d9"
      },
      "outputs": [],
      "source": [
        "# Checking the flower class types.\n",
        "class_names=dataset.classes\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F89K2Gnv-3O"
      },
      "outputs": [],
      "source": [
        "# Train and Test data split. \n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset.targets))), test_size=0.2, stratify=dataset.targets)\n",
        "train_data = torch.utils.data.Subset(dataset, train_indices)\n",
        "test_data = torch.utils.data.Subset(dataset, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTc8_5kuwAdW"
      },
      "outputs": [],
      "source": [
        "train_loader=DataLoader(train_data,batch_size=10,shuffle=True)\n",
        "test_loader=DataLoader(test_data,batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhcdYzW7wCEx",
        "outputId": "5a08bae4-cc5d-4039-e3f2-6a2457a2e81a"
      },
      "outputs": [],
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DYug9QmwDb6",
        "outputId": "ac1d5b68-85cc-44ab-d806-58ce238395f6"
      },
      "outputs": [],
      "source": [
        "# Preview of the datasets. \n",
        "for images, labels in train_loader:\n",
        "    break\n",
        "#print the labels\n",
        "print('Label:', labels.numpy())\n",
        "print('Class:', *np.array([class_names[i] for i in labels]))\n",
        "\n",
        "im=make_grid(images,nrow=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "9PJM4MUowFAZ",
        "outputId": "ac0dab04-3329-496e-f0de-97f15c83031c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DpSEbX4wGjZ"
      },
      "outputs": [],
      "source": [
        "# Inverse Normalization. \n",
        "inv_normalize=transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],\n",
        "                                     std=[1/0.229,1/0.224,1/0.225])\n",
        "im=inv_normalize(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "vI94skaTwIeK",
        "outputId": "9e00f32a-cf3a-4bf1-cbf8-cbc388e4c2fb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVa0CwMlwKRI"
      },
      "outputs": [],
      "source": [
        "# Convolutional Network - Baseline\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, classes):\n",
        "        super().__init__()\n",
        "        self.num_classes=classes\n",
        "        self.conv1=nn.Conv2d(3,6,3,1)\n",
        "        self.conv2=nn.Conv2d(6,16,3,1)\n",
        "        self.fc1=nn.Linear(16*54*54,120) \n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3=nn.Linear(84,20)\n",
        "        self.fc4=nn.Linear(20,self.num_classes)\n",
        "    def forward(self,X):\n",
        "        X=F.relu(self.conv1(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=F.relu(self.conv2(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=X.view(-1,16*54*54)\n",
        "        X=F.relu(self.fc1(X))\n",
        "        X=F.relu(self.fc2(X))\n",
        "        X=F.relu(self.fc3(X))\n",
        "        X=self.fc4(X)\n",
        "        \n",
        "        return F.log_softmax(X, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thnr0iFSwNzV"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "CNNmodel=ConvolutionalNetwork(num_classes)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(CNNmodel.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yoqv5LPnwQsM",
        "outputId": "7187e348-b956-41dd-d187-4961d234e872"
      },
      "outputs": [],
      "source": [
        "CNNmodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-jnIKVGwRjK",
        "outputId": "a108da0e-d786-4c9b-fa07-13745f7eaa8b"
      },
      "outputs": [],
      "source": [
        "# Counting of number of parameters in the model.\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>8}')\n",
        "    print(f'________\\n{sum(params):>8}')\n",
        "count_parameters(CNNmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umcXykKiwTO8",
        "outputId": "1b82bcd8-60bb-4a77-b4ee-3aa8617fe5da"
      },
      "outputs": [],
      "source": [
        "# Learning Schema.\n",
        "import time\n",
        "start_time=time.time()\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "train_correct=[]\n",
        "test_correct=[]\n",
        "epochs=5\n",
        "\n",
        "for i in range(epochs):\n",
        "    trn_corr=0\n",
        "    tst_corr=0\n",
        "    for b, (X_train,y_train) in enumerate(train_loader):\n",
        "        b+=1                                            \n",
        "        y_pred=CNNmodel(X_train)\n",
        "        loss=criterion(y_pred,y_train)\n",
        "\n",
        "        predicted=torch.max(y_pred.data,1)[1]\n",
        "        batch_corr=(predicted==y_train).sum()\n",
        "        trn_corr+=batch_corr\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if b%200==0:\n",
        "            print(f\"epoch: {i} loss: {loss.item} batch: {b} accuracy: {trn_corr.item()*100/(10*b):7.3f}%\")\n",
        "    loss=loss.detach().numpy()\n",
        "    train_losses.append(loss)\n",
        "    train_correct.append(trn_corr)\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for b, (X_test,y_test) in enumerate(test_loader):\n",
        "            y_val=CNNmodel(X_test)\n",
        "            loss=criterion(y_val,y_test)\n",
        "            \n",
        "            predicted=torch.max(y_val.data,1)[1]\n",
        "            btach_corr=(predicted==y_test).sum()\n",
        "            tst_corr+=btach_corr\n",
        "            \n",
        "        loss=loss.detach().numpy()\n",
        "        test_losses.append(loss)\n",
        "        test_correct.append(tst_corr)\n",
        "        \n",
        "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "VNkT5PRDwZPJ",
        "outputId": "d9b687b4-a437-4b82-bfa9-c68a6e2937ba"
      },
      "outputs": [],
      "source": [
        "# Plotting loss over time. \n",
        "plt.plot(train_losses,label=\"train_losses\")\n",
        "plt.plot(test_losses,label=\"test_losses\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "_GjQkrBmwfIP",
        "outputId": "e142a4a2-be9e-4aa0-e140-6351c251d607"
      },
      "outputs": [],
      "source": [
        "x=100\n",
        "im = inv_normalize(test_data[x][0])\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIqcrg3ewg6G",
        "outputId": "833c3e30-c47a-4d4c-a502-a2fc0a3e3915"
      },
      "outputs": [],
      "source": [
        "test_data[x][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sMnmF4pwi0m",
        "outputId": "7318b67a-3a69-4783-8453-1f909ef54176"
      },
      "outputs": [],
      "source": [
        "# Prediction for one of the samples. \n",
        "CNNmodel.eval()\n",
        "with torch.no_grad():\n",
        "    new_pred=CNNmodel(test_data[x][0].view(1,3,224,224)).argmax()\n",
        "print(f'Predicted value: {new_pred.item()} {class_names[new_pred.item()]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFq_CVljVDrL"
      },
      "source": [
        "##FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghA9KF-1UgBH"
      },
      "outputs": [],
      "source": [
        "  #The code from https://cloudstor.aarnet.edu.au/plus/s/PcSc67ZncTSQP0E can be used to count flops\n",
        "  #Download the code.\n",
        "  !wget -c https://cloudstor.aarnet.edu.au/plus/s/hXo1dK9SZqiEVn9/download\n",
        "  !mv download FLOPs_counter.py\n",
        "  #!rm -rf download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq22AiKTVHMx"
      },
      "outputs": [],
      "source": [
        "from FLOPs_counter import print_model_parm_flops\n",
        "input = torch.randn(1, 3, 224, 224) # The input size should be the same as the size that you put into your model \n",
        "#Get the network and its FLOPs\n",
        "num_classes = 5\n",
        "model = ConvolutionalNetwork(num_classes)\n",
        "print_model_parm_flops(model, input, detail=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Flower_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
